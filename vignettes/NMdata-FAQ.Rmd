---
title: "NMdata FAQ"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{NMdata FAQ}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
header-includes:
- \usepackage{ae}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
 ,fig.width=7)

knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60), tidy=TRUE)
```


Built `r Sys.Date()` using NMdata `r packageVersion("NMdata")`.

## General `NMdata` questions

### How do I install NMdata?
To get the most up to date version of `NMdata`, do the following from
within R:

```{eval=FALSE}
library(remotes)
install_github("philipdelff/NMdata")
library(NMdata)
```

In a production environment, use a [github
release](https://github.com/philipdelff/NMdata/releases) To install
`NMdata 0.0.6.1` release, do

```{eval=FALSE}
library(remotes)
install_github("philipdelff/NMdata@v0.0.6.1")
library(NMdata)
```

If you need to archive a script that is dependent on a feature or bug
fix which is only in the master branch, request a release. 


### What about NMdata dependencies?
`NMdata` depends on `data.table` only, and `data.table` does not have
any dependencies. R 3.0 or later is required, that's all (yes, you can
actually run this on pretty old R installations without any
difference).

### I use another tool that automatically reads my data. Should I be interested in NNdata?
The data creation tools in `NMdata` may still be interesting. If
another tool is working well for a project, you may not have any
reason to use `NMscanData` for it. However, a lot of the time those
tools have certain requirements to how datasets are constructed and
especially how data is exported from Nonmem (`$TABLE`). If a Nonmem
run does not live up to those requirements, and you want to look at
the run results, `NMscanData` will let you do that without you having
to "correct" your `$TABLE` statements and wait for Nonmem to run
again. 

Also, in other cases `NMscanData` can save you a lot of time and
frustration even if you have your own routines that make `NMdata`
unnecessary. If you want to read your old Nonmem runs that were done a
little differently, someone else's work, or you want to quickly read a
lot of runs done by different people for a meta analysis, `NMscanData`
can save you a lot of work, time and frustration.


### Why is NMdata fast?
`NMdata` is generally fast - all thanks to the incredible `data.table`
package. If you don't use `data.table` already, it may even seem extremely
fast. If you are noticing some circumstances where `NMdata` seems
slow, I am very curious to hear about it.

### So NMdata uses data.table. Does that mean variables are modified by reference? 
NMdata will never modify variables in your workspace by reference, so
don't worry. NMdata definitely modify variables by reference
internally but this will never affect your workspace. This has a
slight performance price, but using `NMdata` must be easy for R user
at all levels of experience.  If you don't understand what this is all
about, you're fine.

### I want to use a tool from NMdata, but how does it integrate with dplyr or data.table?
Every function in `NMdata` has an argument called `as.fun`. You
can provide a function in this argument which will be applied to data
before returnin it.

You can get a tibble if you work with `dplyr`/`tidyverse` tools: 

```{r,eval=F}
NMscanData(...,as.fun=tibble::as_tibble)
```

Under the hood, NMdata is implemented in `data.table`, and in fact the
default is to convert to `data.frame` before returning the output. So
if you want `data.table`, use `"none"` to avoid the conversion

```{r,eval=F}
NMscanData(...,as.fun="none")
```

Using `as.fun=as.data.table` wold work but is not recommended, because
that would do an unnecessary deep copy of data.

If you want to change the behaviour generally for the session and omit
the `as.fun` argument, you can do this by this option:

```{r,eval=F}
## for tibbles
options(NMdata.as.fun=tibble::as_tibble)
## for data.table
options(NMdata.as.fun="none")
```

And all `NMdata` functions (that return data) should now return
tibbles or data.tables. If you use `options` to control this, for
reproducibility please
do so explecitly in your code and not in your `.Rprofile` or
similar. 

### Can I request a feature?
Please open an issue on [github](https://github.com/philipdelff/NMdata/issues).

### Any plans on including some plotting functions?
No. See the question above about dependencies. If NMdata were extended
with plotting features, it would become dependent on a number of
packages, and backward compatibility would be very dificult to
ensure. 

The only way to provide plotting features for output from `NMdata`
functions, would be to launch a separate package. But actually, I
rarely need much code to get the plots I want based on the format
returned by `NMscanData` and maybe a call to `findCovs` or `findVars`.


## Questions specific to data reading tools 
### What if I don't use PSN, and my control stream files are named differently?
`NMscanData` needs the path to the output control stream (technically, the
input control stream will work too, but this is not recommended). It has no requirement to the naming of the
output control stream. In order to find the input data, it needs the
input control stream as well, and it will automatically find it based
on the output control stream path and an assumed naming convention
based on PSN (which is that the output control stream is called .lst
and the input control stream is located next to it called .mod). 
This naming convention can easily be configured using the
`NMdata.file.mod` option. 

Another commonly used file structure is to have each run in a separate
folder. Say the output control stream input control stream is always
located next to the output control stream, you can use

```{r,eval=FALSE}
options(NMdata.file.mod=function(file) file.path(dirname(file),"input.txt"))
```

Then `NMscanData` will automatically find the input control stream
when you supply the path to the output control stream in the `file`
argument.


### What is "input" and output data?
- What is referred to as "input data" in `NMdata` documentation is the
datafile read in the `$DATA` or `$INFILE`. 
- What is referred to as "output data" in the same documentation is the
totality of files written by `$TABLE` statements. 

Notice especially, "output data" does not refer to any of the files
automatically written by Nonmem such as `.phi`, `.ext`, `.cov` etc.

### Does NMdata read .phi, .ext, .cov and other files generated by Nonmem?
No. Reading this data is often very useful, but there are other tools
out there that do this (e.g. `nonmem2R`).
